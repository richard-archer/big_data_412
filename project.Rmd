---
title: "project"
author: "Grace"
date: "June 7, 2019"
output: html_document
---

#Reading, Cleaning Data
```{r setup, include=FALSE}

setwd("E:/3rd/Spring/Big Data/project")

knitr::opts_chunk$set(echo = TRUE, 
                      #include = TRUE, 
                      fig.width = 6, fig.height = 4,
                      results='hide',
                      warning = FALSE,
                      cache = TRUE,
                      digits = 3,
                      width = 48) 

havingIP <- function() {
  if (.Platform$OS.type == "windows") {
    ipmessage <- system("ipconfig", intern = TRUE)
    } else {
      ipmessage <- system("ifconfig", intern = TRUE)
      }
  validIP <- 
    "((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)[.]){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)"
  any(grep(validIP, ipmessage))
}
havingIP() #fuck my laptop

library(knitr)
library(dplyr)
library(tidyverse)
library(haven)
library(gamlr)
library(igraph)
library(readxl)
library(openintro)
library(tree)
library(randomForest)
library(plyr)
library(arules)
library(textir)
```


```{r read in data }
#read in survey data
ts <- read_dta("timeseries_2016_dta.zip")

#read in the turnout data
upto2k14<-read.csv("1980-2014_nge_turnout.csv", skip=1, header=T)
to2k16<-read.csv("2016_nge_turnout.csv", skip=1, header=T)
to2k18<-read.csv("2018_nge_turnout.csv", skip=1, header=T)

#columns to be filtered out
bad_2k14<-c("ICPSR.State.Code", "Alphanumeric.State.Code")
bad_other<-c("State.Results.Website", "Status")
```


```{r combine turnout and regions}
#Combine all the turnout info and add regions

#upto2k14 column names
upto2k14<-upto2k14[,!(names(upto2k14)%in% bad_2k14)]
colnames(upto2k14) <- c("Year", 
                        "State",
                        "VEP.Total.Ballots.Counted",
                        "VEP.Highest.Office",
                        "VAP.Highest.Office",
                        "Total.Ballots.Counted",
                        "Highest.Office",
                        "VEP",
                        "VAP",
                        "non-citizen",
                        "Prison",
                        "Probation",
                        "Parole",
                        "TIFelon",
                        "Overseas")
upto2k14 <-
  upto2k14 %>% 
  filter(State != "United States") %>%
  mutate(Abbreviation = if_else(State == "District of Columbia", 
                                           "DC", state2abbr(State)))

#to2k16 column names
to2k16<-to2k16[,!(names(to2k16)%in% bad_other)]
to2k16$Year<-2016
colnames(to2k16) <- c("State",
                      "VEP.Total.Ballots.Counted",
                      "VEP.Highest.Office",
                      "VAP.Highest.Office",
                      "Total.Ballots.Counted",
                       "Highest.Office",
                      "VEP",
                        "VAP",
                        "non-citizen",
                        "Prison",
                       "Probation",
                       "Parole",
                      "TIFelon",
                      "Overseas",
                      "Abbreviation",
                      "Year")

#to2k18 column names
to2k18<-to2k18[,!(names(to2k18)%in% bad_other)]
to2k18$Year<-2018
colnames(to2k18) <- c("State",
                      "VEP.Total.Ballots.Counted",
                      "VEP.Highest.Office",
                      "Source",
                      "Total.Ballots.Counted",
                       "Highest.Office",
                        "VEP",
                        "VAP",
                        "non-citizen",
                        "Prison",
                       "Probation",
                       "Parole",
                        "TIFelon",
                      "Overseas",
                      "Abbreviation",
                      "Year")

turnout <- 
  rbind.fill(upto2k14, to2k16, to2k18) %>%
  filter(State != "United States") %>%
  select(-c("Source"))

#regions
#dataframes of regions from aes data, done manually
NE<-data.frame(Abbreviation=c("CT", "ME", "MA", "NH", "NJ", "NY", "PA", "RI", "VT"))
NC<-data.frame(Abbreviation=c("IL", "IN", "IA", "KS", "MI", "MN", "MO", "NE", "ND"
, "OH", "SD", "WI"))
South<-data.frame(Abbreviation=c("AL", "AR", "DE", "DC", "FL", "GA", "KY", "LA", "MD", "MS", "NC", "OK", "SC","TN", "TX", "VA", "WV"))
West<-data.frame(Abbreviation=c("AK", "AZ", "CA", "CO", "HI", "ID", "MT", "NV", "NM", "OR", "UT", "WA", "WY"))

#name the regions
NE$Region<-"NE"
NC$Region<-"NC"
South$Region<-"South"
West$Region<-"West"

#combine the regions with region labels
reg_converter<-rbind(NE, NC, South, West)

#add regions to turnout data
turnout_reg<-merge(turnout, reg_converter, by="Abbreviation")
```

We drop five cases between turnout and turnout_reg--what are these? They're not DC or US.


#Campaign Finance
```{r campaign finance}
cf15_16<-read.csv("Contributions_15-16.csv")
cf_cols<- c("committee_name", 
            "report_year", 
            "entity_type", 
            "recipient_name", 
            "recipient_state", 
            "disbursement_description", 
            "disbursement_date", 
            "disbursement_amount", 
            "fec_election_type_desc", 
            "fec_election_year")
cf15_16 <- cf15_16[, cf_cols]
unique(cf15_16$committee_name)

com_agg <-aggregate(cf15_16$disbursement_amount, 
                    by=list(Comittee=cf15_16$committee_name), 
                    sum)
colnames(com_agg)[colnames(com_agg)=="x"]<-"Spending"
cut_df<-as.data.frame(com_agg)[com_agg$Spending>1000000,]

#figure out which candidates are most importatnt
cut_df$Comittee

#removes rows with NaN in specific column
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}

#important candidate comittees, based on party
#Can we do cut_df$Committee?
dems <- data.frame(cands=c("OBAMA FOR AMERICA", 
                           "HILLARY FOR AMERICA", 
                           "BERNIE 2016", 
                           "COMMITTEE TO ELECT LLOYD KELSO PRESIDENT", 
                           "ROCKY 2016 LLC", 
                           "O'MALLEY FOR PRESIDENT", 
                           "WILLIE WILSON 2016"))
reps <- data.frame(cands=c("CRUZ FOR PRESIDENT", 
                           "CARLY FOR PRESIDENT", 
                           "CARSON AMERICA", 
                           "DONALD J. TRUMP FOR PRESIDENT, INC.", 
                           "JEB 2016, INC.", 
                           "MARCO RUBIO FOR PRESIDENT", 
                           "CHRIS CHRISTIE FOR PRESIDENT INC", 
                           "PERRY FOR PRESIDENT INC", 
                           "SANTORUM FOR PRESIDENT 2016", 
                           "LINDSEY GRAHAM 2016", 
                           "RAND PAUL FOR PRESIDENT, INC.", 
                           "HUCKABEE FOR PRESIDENT, INC.", 
                           "SCOTT WALKER INC", 
                           "KASICH FOR AMERICA INC", 
                           "FRIENDS OF HERMAN CAIN INC"))
ind <- data.frame(cands=c("MCMULLIN FOR PRESIDENT COMMITTEE INC.", 
                          "GARY JOHNSON 2016", 
                          "JILL STEIN FOR PRESIDENT"))
#assign party labels 
cf15_16$party[cf15_16$committee_name %in% dems$cands]<-"D"
cf15_16$party[cf15_16$committee_name %in% reps$cands]<-"R"
cf15_16$party[cf15_16$committee_name %in% ind$cands]<-"I"

#remove NaN from parties (ie remove not important candidates)
cf15_16<-completeFun(cf15_16, "party")

#aggregate based on party and state
com_agg2<-aggregate(disbursement_amount~party+recipient_state, cf15_16, sum)

#change state colname for matching purposes
colnames(com_agg2)[colnames(com_agg2)=="recipient_state"]<-"Abbreviation"
```

```{r combine 2016 turnout and finance data}
#just 2016 turnout info
turnout_16<-subset(turnout_reg, Year==2016)
#disbursements by state
dem_CF<-subset(com_agg2, party=="D", select=c("disbursement_amount", "Abbreviation"))
rep_CF<-subset(com_agg2, party=="R", select=c("disbursement_amount", "Abbreviation"))
ind_CF<-subset(com_agg2, party=="I", select=c("disbursement_amount", "Abbreviation"))

#Add CF to turnout df by merging each parties spending by state 
#Method 2
com_agg3 <-
  com_agg2 %>%
  spread(party, disbursement_amount)
turnout_cf <- 
  merge(turnout_16, com_agg3, by="Abbreviation")
```
Ok so a question here: why does our com_agg3 (from com_agg) have abbreviations that aren't real? ZZ is not a state, and I suck at geography but we don't have 75 states. OMG ZZ IS THE *DEEP* STATE??!!

```{r adding in campaign results}
#election results by state
results<-read_excel("G-politicians.xls")
#clean_names(results)
colnames(results)[colnames(results)=="state_abbreviation"]<-"Abbreviation"

#fix some weird names so its all D/R
results$`Balloted party(ies)`[(results$`Balloted party(ies)`=="Republican, American Independent")|(results$`Balloted party(ies)`=="Conservative, Republican")]<-"Republican"

results$`Balloted party(ies)`[(results$`Balloted party(ies)`=="Democratic-Nonpartisan League")|(results$`Balloted party(ies)`=="Democratic-Farmer Labor")|(results$`Balloted party(ies)`=="Working Families, Women's Equality, Democratic")]<-"Democratic"

#only take presidential candidates who are D/R
results<-subset(results,(`Office abbreviation`=="P")&((`Balloted party(ies)`=="Republican")|(`Balloted party(ies)`=="Democratic")))

#here's our popular vote margin
resultsm <-
  results %>%
  select("Last",
         "Popular vote",
         "State abbreviation") %>%
  spread(Last, `Popular vote`) %>%
  mutate(margin = Clinton-Trump,
         party_win = if_else(margin > 0, "D", "R"),
         Abbreviation = `State abbreviation`)

#merge vote margin and winner with turnout/CF df
CF_pop <- 
  merge(turnout_cf, resultsm, by="Abbreviation")%>%
  select("Abbreviation",
         "Highest.Office",
         "D",
         "I",
         "R",
         "margin",
         "Clinton",
         "Trump",
         "party_win") %>%
  mutate(vote_per = as.numeric(as.character(gsub(',', '', Highest.Office))),
         margin_per = margin/vote_per,
         cf = D + I + R)
#alright at this point, cf_pop has party spending, total spending, and who won
list_cols<-c("version", "V160001", "V160001_orig")
weights<-c("V160102", "V160101", "V160102f", "V160101f", "V160102w", "V160101w")
strata_weights<-c("V160201", "V160201f", "V160201w", "V160202", "V160202f", "V160202w")
interview_type<-c("V160501", "V160502")

ts1 <- mutate(ts, Abbreviation = V161010e) %>%
  select(-c(list_cols, weights, strata_weights, interview_type))


#drop all the missing values @riya help
#ts + campaign finance, total spending, results by state
ts3 <- 
  merge(ts1, CF_pop, by = "Abbreviation")
```


```{r}
#Exploratory stuff: make a graph of spending over time


```

#Resolve Missing Data: Grace is working on this
```{r}
#Drop every NA value (-1 through -7) - the dumbass way
ts_n <- 
  ts3 %>% 
#keep -8 and -9 bc those are meaningful 
  
  
#reassign -8 and -9 to -1

```


#Campaign Finance Take 2
```{r campaign finance data individualized}
#propublica individualized funding
pro_filing <- 
  read.delim("ftf-all-filings.tsv", sep = "\t") %>%
  select(-c(url,thumbnail_url, dc_slug)) %>%
  mutate(year = as.Date(upload_date, "%Y"))  %>%
  filter (year < "2012-11-06",
         !is.na(gross_amount))
#we go from 66k to 16k cases by this point - dropping 50k cases ain't great
#our cycle cutoff is November 6, 2012 because that's election day for 2012
#in hindsight this is useless because it's 2012. fuck me.
 

#FEC individualized campaign finance data
#this is too large to view or download 

#method 1: nope. 
# FILES <- list.files( pattern = ".txt")
# for (i in 1:length(FILES)) {
# FILE=read.table(file=FILES[i],header=T)
# write.csv(FILE,file=paste0("/home/dennis/Desktop/",sub(".txt","",FILES[i]),".csv"))
# }

# method 2: why did I even think that would work
# filing <- read.table("itcont.txt", sep ="|")

#method 3: readr is a speedy boi 
install.packages("readr")
library(readr)

#what's the diff between delim and tsv
filing <- read_tsv("itcont.txt")
separate(filing, col, into, sep = "|", remove = TRUE, convert = FALSE) #this doesn't work.

#Clinton announced in April 12, 2015
#Trump announced June 16, 2015
#Election day is November 8, 2016
  

#committee to candidate conversion, because filing only has committees
c2c <- 
  read.csv("com_to_cand.csv")%>%
  mutate(cand = tolower(Candidate))
  
#only select the individual filings for Clinton and Trump
filing1 <-
  filing %>%
  mutate(care = if_else(committee %in% c2c$cand, 1,0)) %>%
  filter(mutate == 1)


#once the filing dataframe separates into multiple columns, we should be in business 
```


```{r threshold for campaign spending}
threshold <- function(k, dat) {
  return( )
}

```


#Double-LASSO
```{r}
#d = campaign finance, dhat = , V = margin
#bc we want to see whether campaign finance is helpful in predicting outcome

d <- ts3$cf
spm <- sparse.model.matrix(~., data=ts3)[,-1]
V <- ts3$margin

double_lasso <- gamlr(cbind(d,dhat,ts3), V, free=2)

plot(double_lasso)
coef(double_lasso)["d",]

```

#Possibly use this to run a simple lasso if we're really fucked for time

This chunk below basically determines the difference between intending to vote and actually turning out to vote. That's kind of interesting--we should see if we can use that voter turnout margin to predict the party that wins in that region. (Liberals are cocky fucks interpretation). Add as an extra layer, post overall KNN or double LASSo

```{r simple lasso fuck}
#V161011 <- registered to vote
#V161010e <- state abr
#V161019 <- registered party
#V161030 <- intend to vote
#V161031 <- candidate intended
#V161241 <- is religion important

subset(ts, V161030 = 1) #intending to vote in 2016
subset(turnout_reg, Year==2016) #turnout in 2016 
#compare by state to get margin, then use to predict party outcome

ts_vote <-
  ts3 %>%
  mutate(intend_vote = if_else(V161030 = 1, 1,0),
         intend_d = if_else(intend_vote = 1 & V161019 = 1, 1, 0),
         intend_r = if_else(intend_vote = 1 & V161019 = 2, 1, 0))
```



#KNN Analysis 
knn.impute took over ten minutes before I just killed it--what is happening??
Remember to explain the reason we're treating NA -1 to -7 vs. the other NA values. 
```{r knn analysis}
#-7 to -1 correspond to NaN, will use these as references
#-8, -9, 998, 999 will be imputed with KNN
ts[ts>100]<-NaN
ts[(ts<0)&(ts>-8)]<-NaN
na_count1 <-sapply(ts, function(y) sum(length(which(is.na(y))))) #this fucker right here
na_count1/nrow(ts)

knn.impute(as.matrix(ts[na_count1/nrow(ts)<0.5]), k=5) #kNNImpute in imputation ?
na_count2 <-sapply(ts, function(y) sum(length(which(is.na(y)))))
na_count2/nrow(ts)
```




#PCA Analysis
```{r pca analysis}
rel<-aggregate(ts[,!(names(ts) %in% c("V161010e", "version"))], by=list(Rel=ts$V161241), mean)
rel$V162084

#pca<-prcomp(rel, scale=T)
#pca
na_count <-sapply(ts, function(y) sum(length(which(is.na(y)))))

#na_count["V161010e"]/nrow(ts)
na_count[na_count>0.00001]

rel_na<-sapply(rel, function(y) sum(length(which(is.na(y)))))

bad_names<-names(rel_na)[rel_na>0]

new_rel<-aggregate(ts[,!(names(ts) %in% c(bad_names, "V161010e", "version"))], by=list(Rel=ts$V161241), mean)

#so what I did here was dropped all columns that had the same value for each row. this is what made the pca work - riya
new_rel <- new_rel[, sapply(new_rel, function(col) length(unique(col))) > 1] 
new_rel

pca<-prcomp(new_rel, scale=T)
zpca <- predict(pca)

lassoPCR <- cv.gamlr(zpca, y=)
```


#Random Forest

We now have numeric total votes column--just need a fucking random forest now
```{r decision tree with finance}
#decision tree with finances

tree_ex<-tree(margin~vote_per+D+R+I, data=CF_pop, mincut =1)

plot(tree_ex)
text(tree_ex, splits = TRUE)
#kDTree(tree_ex)

```
